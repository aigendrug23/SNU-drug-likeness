{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code implemented from: https://github.com/lucidrains/graph-transformer-pytorch\n",
    "- pip install einops\n",
    "- pip install rotary-embedding-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--device', type=str, default='cuda:2')\n",
    "# check gpu status with: gpustat -cuFi 1\n",
    "\n",
    "parser.add_argument('--hdim', type=int, default=64) #hidden dimension\n",
    "parser.add_argument('--edge_dim', type=int, default=None)\n",
    "parser.add_argument('--n_layers', type=int, default=3)\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1e-3)\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'GraphTransformer_h{args.hdim}e{args.edge_dim}l{args.n_layers}_lr{args.lr}_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'einops'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3bfcd111b6e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraph_transformer_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/project/aigenintern/aigenintern1/23-2/graph-transformer-pytorch/graph_transformer_pytorch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraph_transformer_pytorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_transformer_pytorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/project/aigenintern/aigenintern1/23-2/graph-transformer-pytorch/graph_transformer_pytorch/graph_transformer_pytorch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meinops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrotary_embedding_torch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRotaryEmbedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_rotary_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'einops'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from graph_transformer_pytorch import GraphTransformer\n",
    "import torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from utils_dm import EarlyStopper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from torch_geometric.utils.smiles import from_smiles\n",
    "from geometric_utils import from_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole_df = pd.read_csv('../../../2023-2/ETC/molecule_stability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3498"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#whole_data = [from_smiles(smi) for smi in whole_df.SMILES]\n",
    "#len(whole_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(whole_data, '../../../2023-2/processed_data/graph_transformer/graph_transformer_whole_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = torch.load('../../../2023-2/processed_data/graph_transformer/graph_transformer_whole_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataset\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset, labels):\n",
    "        self.dataset = dataset\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = whole_df[['MLM','HLM']].values\n",
    "dataset = MyDataset(whole_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2800 349 349\n",
      "2800 349 349\n"
     ]
    }
   ],
   "source": [
    "# split dataset\n",
    "test_ratio = 0.1\n",
    "valid_ratio = 0.1\n",
    "\n",
    "test_len = int(len(dataset)*test_ratio)\n",
    "valid_len = int(len(dataset)*valid_ratio)\n",
    "train_len = len(dataset) - valid_len - test_len\n",
    "print(train_len, valid_len, test_len)\n",
    "\n",
    "trainset,validset,testset = torch.utils.data.random_split(dataset, [train_len,valid_len,test_len],\n",
    "                                      torch.Generator().manual_seed(42))\n",
    "print(len(trainset), len(validset), len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataloader\n",
    "trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=0, drop_last=False,\n",
    "                        generator=torch.Generator().manual_seed(42))\n",
    "validloader = DataLoader(validset, batch_size=args.batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
    "testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.utils import to_dense_batch, to_dense_adj\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "class GraphTransformer_MTL(nn.Module):\n",
    "    def __init__(self, dim, depth, edge_dim = None, tasks=2, with_feedforwards = True, gated_residual = True, rel_pos_emb = False):\n",
    "        super().__init__()\n",
    "        edge_dim = default(edge_dim, dim)\n",
    "        self.encoder = GraphTransformer(dim = dim, depth = depth, edge_dim=edge_dim, \n",
    "                                        with_feedforwards=with_feedforwards, gated_residual=gated_residual, \n",
    "                                        rel_pos_emb=rel_pos_emb)\n",
    "        \n",
    "        self.node_feature_encoder = nn.Linear(9, dim)\n",
    "        self.edge_feature_encoder = nn.Linear(3, edge_dim)\n",
    "        self.pred_heads = nn.ModuleList()\n",
    "        for _ in range(tasks):  # tasks = 2 \n",
    "            self.pred_heads.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Linear(dim, dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(dim, dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(dim, 1)\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    def encode_features(self, batch):\n",
    "        z_x = self.node_feature_encoder(batch.x.float())\n",
    "        z_e = self.edge_feature_encoder(batch.edge_attr.float())\n",
    "        nodes, mask = to_dense_batch(z_x, batch.batch)\n",
    "        edges = to_dense_adj(batch.edge_index, batch.batch, edge_attr=z_e)\n",
    "        return nodes, edges, mask\n",
    "\n",
    "    def forward(self, batch):\n",
    "        nodes, edges, mask = self.encode_features(batch)\n",
    "        nodes, edges = self.encoder(nodes, edges, mask = mask)\n",
    "\n",
    "        res = scatter_mean(nodes[mask], batch.batch, dim=0)\n",
    "        \n",
    "        preds = []\n",
    "        for head in self.pred_heads:\n",
    "            out = head(res)\n",
    "            preds.append(out)\n",
    "        return torch.cat(preds, dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphTransformer_MTL(dim=args.hdim, depth=args.n_layers, edge_dim=args.edge_dim).to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "criterion = nn.MSELoss()    # regression \n",
    "early_stopper = EarlyStopper(patience=20,printfunc=print,verbose=True,path=f'ckpts/{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, args, optimizer=optimizer, criterion=criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, label in trainloader:\n",
    "        batch = batch.to(args.device)\n",
    "        label = label.to(args.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch)\n",
    "        \n",
    "        loss1 = criterion(pred[:,0].squeeze(), label[:,0].squeeze())\n",
    "        loss2 = criterion(pred[:,1].squeeze(), label[:,1].squeeze())\n",
    "        loss = (loss1 + loss2)/2\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, args, return_output=False, criterion=criterion):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    ys = []\n",
    "    with torch.no_grad():\n",
    "        for batch, label in loader:\n",
    "            batch = batch.to(args.device)\n",
    "            label = label.to(args.device)\n",
    "            pred = model(batch)\n",
    "            preds.append(pred)\n",
    "            ys.append(label)\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    ys = torch.cat(ys, dim=0)\n",
    "    \n",
    "    loss1 = criterion(preds[:,0].squeeze(), ys[:,0].squeeze())\n",
    "    loss2 = criterion(preds[:,1].squeeze(), ys[:,1].squeeze())\n",
    "    loss = (loss1 + loss2)/2\n",
    "\n",
    "    if return_output:\n",
    "        return loss.item(), preds, ys\n",
    "    else:\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch1] train_loss: 35.9834, valid_loss: 36.2212\n",
      "[Epoch2] train_loss: 35.8342, valid_loss: 36.5837\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch3] train_loss: 36.4064, valid_loss: 36.0178\n",
      "[Epoch4] train_loss: 36.0012, valid_loss: 36.7574\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch5] train_loss: 35.6902, valid_loss: 35.6540\n",
      "[Epoch6] train_loss: 35.4527, valid_loss: 35.8211\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch7] train_loss: 35.1027, valid_loss: 35.1435\n",
      "[Epoch8] train_loss: 35.0703, valid_loss: 36.3097\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch9] train_loss: 34.9416, valid_loss: 34.9781\n",
      "[Epoch10] train_loss: 34.6726, valid_loss: 36.1143\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch11] train_loss: 34.4224, valid_loss: 35.6266\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch12] train_loss: 34.4940, valid_loss: 35.0928\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch13] train_loss: 34.5630, valid_loss: 34.8735\n",
      "[Epoch14] train_loss: 34.1196, valid_loss: 34.3184\n",
      "[Epoch15] train_loss: 33.9026, valid_loss: 35.4201\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch16] train_loss: 34.1643, valid_loss: 35.4547\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch17] train_loss: 33.9314, valid_loss: 34.2817\n",
      "[Epoch18] train_loss: 33.5525, valid_loss: 33.6094\n",
      "[Epoch19] train_loss: 34.0255, valid_loss: 34.0543\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch20] train_loss: 33.5520, valid_loss: 33.7997\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch21] train_loss: 33.7168, valid_loss: 34.0000\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch22] train_loss: 33.5833, valid_loss: 33.5196\n",
      "[Epoch23] train_loss: 34.0986, valid_loss: 33.8450\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch24] train_loss: 34.8724, valid_loss: 35.2921\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch25] train_loss: 33.5423, valid_loss: 33.8768\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch26] train_loss: 33.4304, valid_loss: 34.0900\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch27] train_loss: 33.3235, valid_loss: 33.7361\n",
      "EarlyStopping counter: 5/20\n",
      "[Epoch28] train_loss: 33.0075, valid_loss: 33.4554\n",
      "[Epoch29] train_loss: 32.8357, valid_loss: 33.2596\n",
      "[Epoch30] train_loss: 33.0786, valid_loss: 33.7989\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch31] train_loss: 32.9712, valid_loss: 33.6262\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch32] train_loss: 32.6110, valid_loss: 33.5864\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch33] train_loss: 32.8136, valid_loss: 34.0465\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch34] train_loss: 32.4720, valid_loss: 33.9392\n",
      "EarlyStopping counter: 5/20\n",
      "[Epoch35] train_loss: 32.5573, valid_loss: 33.7481\n",
      "EarlyStopping counter: 6/20\n",
      "[Epoch36] train_loss: 32.3913, valid_loss: 34.2555\n",
      "EarlyStopping counter: 7/20\n",
      "[Epoch37] train_loss: 32.9192, valid_loss: 33.9537\n",
      "EarlyStopping counter: 8/20\n",
      "[Epoch38] train_loss: 32.4277, valid_loss: 34.1963\n",
      "EarlyStopping counter: 9/20\n",
      "[Epoch39] train_loss: 32.9290, valid_loss: 34.2748\n",
      "EarlyStopping counter: 10/20\n",
      "[Epoch40] train_loss: 34.4870, valid_loss: 35.4056\n",
      "EarlyStopping counter: 11/20\n",
      "[Epoch41] train_loss: 34.3291, valid_loss: 35.0487\n",
      "EarlyStopping counter: 12/20\n",
      "[Epoch42] train_loss: 33.0274, valid_loss: 33.7476\n",
      "EarlyStopping counter: 13/20\n",
      "[Epoch43] train_loss: 32.7526, valid_loss: 33.9594\n",
      "EarlyStopping counter: 14/20\n",
      "[Epoch44] train_loss: 32.9949, valid_loss: 34.3094\n",
      "EarlyStopping counter: 15/20\n",
      "[Epoch45] train_loss: 32.4486, valid_loss: 33.8647\n",
      "EarlyStopping counter: 16/20\n",
      "[Epoch46] train_loss: 32.5113, valid_loss: 33.2818\n",
      "EarlyStopping counter: 17/20\n",
      "[Epoch47] train_loss: 32.1881, valid_loss: 34.0856\n",
      "EarlyStopping counter: 18/20\n",
      "[Epoch48] train_loss: 32.1103, valid_loss: 34.1027\n",
      "EarlyStopping counter: 19/20\n",
      "[Epoch49] train_loss: 32.4576, valid_loss: 33.7626\n",
      "EarlyStopping counter: 20/20\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "while True:\n",
    "    epoch+=1\n",
    "    train_loss = train(model,trainloader,args)**0.5 # RMSE: root MSE\n",
    "    valid_loss = eval(model,validloader,args)**0.5 # RMSE: root MSE\n",
    "    print(f'[Epoch{epoch}] train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}')\n",
    "    early_stopper(valid_loss,model)\n",
    "    if early_stopper.early_stop:\n",
    "        print('early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded best model \"ckpts/GraphTransformer_h64eNonel3_lr0.001_test.pt\", valid loss: 33.2596\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(early_stopper.path,map_location=args.device))\n",
    "model.eval()\n",
    "print(f'loaded best model \"{early_stopper.path}\", valid loss: {early_stopper.val_loss_min:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test loss: 32.6390\n"
     ]
    }
   ],
   "source": [
    "test_loss=eval(model,testloader,args)**0.5\n",
    "print(f'Final test loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "env1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
