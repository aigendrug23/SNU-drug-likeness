{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--device', type=str, default='cuda:0')\n",
    "# gpustat -cuFi 1\n",
    "parser.add_argument('--seed', type=int, default=42)\n",
    "\n",
    "# learning params\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--hdim', type=float, default=64)\n",
    "parser.add_argument('--batch_size', type=float, default=128)\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/project/aigenintern/2023-1/miniconda3/envs/20232/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from utils_dm import EarlyStopper, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f'Solubility_ECFP_MLP_h{args.hdim}b{args.batch_size}_lr{args.lr}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random seed with 42\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Solubility_AqSolDB'\n",
    "\n",
    "traindf = pd.read_csv(f'../../../2023-2/processed_data/ECFP/{dataset}_train_ECFP_R2B1024.csv', index_col=0)\n",
    "validdf = pd.read_csv(f'../../../2023-2/processed_data/ECFP/{dataset}_valid_ECFP_R2B1024.csv', index_col=0)\n",
    "testdf = pd.read_csv(f'../../../2023-2/processed_data/ECFP/{dataset}_test_ECFP_R2B1024.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Drug_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benzo[cd]indol-2(1H)-one</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.254767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-chlorobenzaldehyde</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.177078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}methyl)-N,N-bis(oxiran-2-ylmethyl)aniline</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.662065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vinyltoluene</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.123150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3-(3-ethylcyclopentyl)propanoic acid</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.286116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarafloxacin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sparfloxacin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sulindac_form_II</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tetracaine</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thymol</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.190000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6988 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0  1  2  3  4  5  6  7  8  \\\n",
       "Drug_ID                                                                         \n",
       "Benzo[cd]indol-2(1H)-one                            0  0  0  0  0  0  0  0  0   \n",
       "4-chlorobenzaldehyde                                0  0  0  0  0  0  0  0  0   \n",
       "4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}methy...  0  0  0  0  0  0  0  0  0   \n",
       "vinyltoluene                                        0  0  0  0  0  0  0  0  0   \n",
       "3-(3-ethylcyclopentyl)propanoic acid                0  0  0  0  0  0  0  0  0   \n",
       "...                                                .. .. .. .. .. .. .. .. ..   \n",
       "sarafloxacin                                        0  0  0  0  0  0  0  0  0   \n",
       "sparfloxacin                                        0  0  0  0  0  0  0  0  0   \n",
       "sulindac_form_II                                    0  0  0  0  0  0  0  0  0   \n",
       "tetracaine                                          0  0  0  0  0  0  0  0  0   \n",
       "thymol                                              0  1  0  0  0  0  0  0  0   \n",
       "\n",
       "                                                    9  ...  1015  1016  1017  \\\n",
       "Drug_ID                                                ...                     \n",
       "Benzo[cd]indol-2(1H)-one                            0  ...     0     0     0   \n",
       "4-chlorobenzaldehyde                                0  ...     0     0     0   \n",
       "4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}methy...  0  ...     0     0     0   \n",
       "vinyltoluene                                        0  ...     0     0     0   \n",
       "3-(3-ethylcyclopentyl)propanoic acid                0  ...     0     0     0   \n",
       "...                                                ..  ...   ...   ...   ...   \n",
       "sarafloxacin                                        0  ...     0     0     0   \n",
       "sparfloxacin                                        0  ...     0     0     0   \n",
       "sulindac_form_II                                    0  ...     0     0     0   \n",
       "tetracaine                                          0  ...     0     0     0   \n",
       "thymol                                              0  ...     0     0     0   \n",
       "\n",
       "                                                    1018  1019  1020  1021  \\\n",
       "Drug_ID                                                                      \n",
       "Benzo[cd]indol-2(1H)-one                               0     0     0     0   \n",
       "4-chlorobenzaldehyde                                   0     0     0     0   \n",
       "4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}methy...     0     1     0     0   \n",
       "vinyltoluene                                           0     0     0     0   \n",
       "3-(3-ethylcyclopentyl)propanoic acid                   0     1     0     0   \n",
       "...                                                  ...   ...   ...   ...   \n",
       "sarafloxacin                                           0     0     0     0   \n",
       "sparfloxacin                                           0     1     0     0   \n",
       "sulindac_form_II                                       0     0     0     0   \n",
       "tetracaine                                             0     0     0     0   \n",
       "thymol                                                 0     0     0     0   \n",
       "\n",
       "                                                    1022  1023     label  \n",
       "Drug_ID                                                                   \n",
       "Benzo[cd]indol-2(1H)-one                               0     0 -3.254767  \n",
       "4-chlorobenzaldehyde                                   0     0 -2.177078  \n",
       "4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}methy...     0     0 -4.662065  \n",
       "vinyltoluene                                           0     0 -3.123150  \n",
       "3-(3-ethylcyclopentyl)propanoic acid                   0     0 -3.286116  \n",
       "...                                                  ...   ...       ...  \n",
       "sarafloxacin                                           0     0 -3.130000  \n",
       "sparfloxacin                                           0     0 -3.370000  \n",
       "sulindac_form_II                                       0     0 -4.500000  \n",
       "tetracaine                                             0     0 -3.010000  \n",
       "thymol                                                 0     0 -2.190000  \n",
       "\n",
       "[6988 rows x 1025 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset, labels):\n",
    "        self.dataset = torch.tensor(dataset).float()\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6988,), 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, train_labels = traindf.values[:, :-1],  traindf.values[:, -1]\n",
    "valid_data, valid_labels = validdf.values[:, :-1],  validdf.values[:, -1]\n",
    "test_data, test_labels = testdf.values[:, :-1],  testdf.values[:, -1]\n",
    "train_labels.shape, (train_labels==1).sum() # check number of positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MyDataset(train_data, train_labels)\n",
    "validset = MyDataset(valid_data, valid_labels)\n",
    "testset = MyDataset(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build dataloader\n",
    "trainloader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=0, drop_last=False,\n",
    "                        generator=torch.Generator().manual_seed(42))\n",
    "validloader = DataLoader(validset, batch_size=args.batch_size, shuffle=False, num_workers=0, drop_last=False)\n",
    "testloader = DataLoader(testset, batch_size=args.batch_size, shuffle=False, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, in_dim, hdim, out_dim=1, dropout=0.1):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_dim,hdim),\n",
    "            nn.LayerNorm(hdim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hdim,hdim)\n",
    "        )\n",
    "        self.prediction_head = nn.Sequential(\n",
    "            nn.LayerNorm(hdim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hdim,out_dim)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.prediction_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dim = trainset[0][0].shape[0]\n",
    "model = NeuralNetwork(in_dim, args.hdim).to(args.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# binary cross entropy nn.BCEWithLogitsLoss()\n",
    "# Mean squared error  nn.MSELoss()\n",
    "\n",
    "early_stopper = EarlyStopper(patience=20,printfunc=print,verbose=True,path=f'ckpts/{model_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, args, optimizer=optimizer, criterion=criterion):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch, label in trainloader:\n",
    "        batch = batch.to(args.device)\n",
    "        label = label.to(args.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(batch).squeeze()\n",
    "        \n",
    "        loss = criterion(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    return train_loss/len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, args, return_output=False, criterion=criterion):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch, label in loader:\n",
    "            batch = batch.to(args.device)\n",
    "            label = label.to(args.device)\n",
    "            pred = model(batch)\n",
    "            preds.append(pred)\n",
    "            labels.append(label)\n",
    "    preds = torch.cat(preds, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    loss = criterion(preds.squeeze(), labels.squeeze())\n",
    "\n",
    "    if return_output:\n",
    "        return loss.item(), preds, labels\n",
    "    else:\n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch1] train_loss: 11.7360, valid_loss: 7.9027\n",
      "[Epoch2] train_loss: 7.0950, valid_loss: 5.9699\n",
      "[Epoch3] train_loss: 6.0525, valid_loss: 5.3284\n",
      "[Epoch4] train_loss: 5.5032, valid_loss: 4.8736\n",
      "[Epoch5] train_loss: 4.9770, valid_loss: 4.3919\n",
      "[Epoch6] train_loss: 4.4753, valid_loss: 3.9833\n",
      "[Epoch7] train_loss: 4.0494, valid_loss: 3.6527\n",
      "[Epoch8] train_loss: 3.6790, valid_loss: 3.3883\n",
      "[Epoch9] train_loss: 3.3574, valid_loss: 3.1803\n",
      "[Epoch10] train_loss: 3.0562, valid_loss: 3.0140\n",
      "[Epoch11] train_loss: 2.8225, valid_loss: 2.8839\n",
      "[Epoch12] train_loss: 2.6373, valid_loss: 2.7772\n",
      "[Epoch13] train_loss: 2.4294, valid_loss: 2.6970\n",
      "[Epoch14] train_loss: 2.2373, valid_loss: 2.6110\n",
      "[Epoch15] train_loss: 2.1012, valid_loss: 2.5676\n",
      "[Epoch16] train_loss: 1.9815, valid_loss: 2.5069\n",
      "[Epoch17] train_loss: 1.8445, valid_loss: 2.4782\n",
      "[Epoch18] train_loss: 1.7323, valid_loss: 2.4353\n",
      "[Epoch19] train_loss: 1.6117, valid_loss: 2.3877\n",
      "[Epoch20] train_loss: 1.5218, valid_loss: 2.3759\n",
      "[Epoch21] train_loss: 1.4123, valid_loss: 2.3391\n",
      "[Epoch22] train_loss: 1.3337, valid_loss: 2.3003\n",
      "[Epoch23] train_loss: 1.2448, valid_loss: 2.3004\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch24] train_loss: 1.2163, valid_loss: 2.2744\n",
      "[Epoch25] train_loss: 1.1542, valid_loss: 2.2532\n",
      "[Epoch26] train_loss: 1.0721, valid_loss: 2.2233\n",
      "[Epoch27] train_loss: 1.0357, valid_loss: 2.2301\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch28] train_loss: 0.9795, valid_loss: 2.2195\n",
      "[Epoch29] train_loss: 0.9406, valid_loss: 2.2474\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch30] train_loss: 0.8749, valid_loss: 2.2193\n",
      "[Epoch31] train_loss: 0.8367, valid_loss: 2.1838\n",
      "[Epoch32] train_loss: 0.8320, valid_loss: 2.1714\n",
      "[Epoch33] train_loss: 0.7923, valid_loss: 2.1941\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch34] train_loss: 0.7687, valid_loss: 2.1788\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch35] train_loss: 0.7406, valid_loss: 2.1919\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch36] train_loss: 0.7278, valid_loss: 2.1829\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch37] train_loss: 0.6992, valid_loss: 2.2039\n",
      "EarlyStopping counter: 5/20\n",
      "[Epoch38] train_loss: 0.6710, valid_loss: 2.1569\n",
      "[Epoch39] train_loss: 0.6489, valid_loss: 2.1655\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch40] train_loss: 0.6442, valid_loss: 2.1640\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch41] train_loss: 0.6324, valid_loss: 2.1563\n",
      "[Epoch42] train_loss: 0.6127, valid_loss: 2.1168\n",
      "[Epoch43] train_loss: 0.6141, valid_loss: 2.1507\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch44] train_loss: 0.5743, valid_loss: 2.1444\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch45] train_loss: 0.5804, valid_loss: 2.1346\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch46] train_loss: 0.5446, valid_loss: 2.1394\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch47] train_loss: 0.5336, valid_loss: 2.1263\n",
      "EarlyStopping counter: 5/20\n",
      "[Epoch48] train_loss: 0.5526, valid_loss: 2.1225\n",
      "EarlyStopping counter: 6/20\n",
      "[Epoch49] train_loss: 0.5414, valid_loss: 2.1053\n",
      "[Epoch50] train_loss: 0.5263, valid_loss: 2.1266\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch51] train_loss: 0.5049, valid_loss: 2.1039\n",
      "[Epoch52] train_loss: 0.4971, valid_loss: 2.1046\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch53] train_loss: 0.5013, valid_loss: 2.1008\n",
      "[Epoch54] train_loss: 0.4950, valid_loss: 2.0900\n",
      "[Epoch55] train_loss: 0.4690, valid_loss: 2.1180\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch56] train_loss: 0.4986, valid_loss: 2.1117\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch57] train_loss: 0.4736, valid_loss: 2.1016\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch58] train_loss: 0.4622, valid_loss: 2.1149\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch59] train_loss: 0.4673, valid_loss: 2.0944\n",
      "EarlyStopping counter: 5/20\n",
      "[Epoch60] train_loss: 0.4491, valid_loss: 2.0901\n",
      "EarlyStopping counter: 6/20\n",
      "[Epoch61] train_loss: 0.4534, valid_loss: 2.1270\n",
      "EarlyStopping counter: 7/20\n",
      "[Epoch62] train_loss: 0.4580, valid_loss: 2.0970\n",
      "EarlyStopping counter: 8/20\n",
      "[Epoch63] train_loss: 0.4459, valid_loss: 2.1077\n",
      "EarlyStopping counter: 9/20\n",
      "[Epoch64] train_loss: 0.4352, valid_loss: 2.1123\n",
      "EarlyStopping counter: 10/20\n",
      "[Epoch65] train_loss: 0.4333, valid_loss: 2.1231\n",
      "EarlyStopping counter: 11/20\n",
      "[Epoch66] train_loss: 0.4502, valid_loss: 2.0947\n",
      "EarlyStopping counter: 12/20\n",
      "[Epoch67] train_loss: 0.4256, valid_loss: 2.0657\n",
      "[Epoch68] train_loss: 0.4311, valid_loss: 2.0831\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch69] train_loss: 0.4315, valid_loss: 2.0875\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch70] train_loss: 0.4162, valid_loss: 2.0833\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch71] train_loss: 0.4267, valid_loss: 2.0771\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch72] train_loss: 0.3952, valid_loss: 2.0573\n",
      "[Epoch73] train_loss: 0.3968, valid_loss: 2.0747\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch74] train_loss: 0.4126, valid_loss: 2.0513\n",
      "[Epoch75] train_loss: 0.4048, valid_loss: 2.0672\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch76] train_loss: 0.4038, valid_loss: 2.0767\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch77] train_loss: 0.4003, valid_loss: 2.0689\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch78] train_loss: 0.3793, valid_loss: 2.0582\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch79] train_loss: 0.3883, valid_loss: 2.0584\n",
      "EarlyStopping counter: 5/20\n",
      "[Epoch80] train_loss: 0.3818, valid_loss: 2.0632\n",
      "EarlyStopping counter: 6/20\n",
      "[Epoch81] train_loss: 0.3922, valid_loss: 2.0763\n",
      "EarlyStopping counter: 7/20\n",
      "[Epoch82] train_loss: 0.3773, valid_loss: 2.0581\n",
      "EarlyStopping counter: 8/20\n",
      "[Epoch83] train_loss: 0.3823, valid_loss: 2.0709\n",
      "EarlyStopping counter: 9/20\n",
      "[Epoch84] train_loss: 0.3752, valid_loss: 2.0893\n",
      "EarlyStopping counter: 10/20\n",
      "[Epoch85] train_loss: 0.3769, valid_loss: 2.0698\n",
      "EarlyStopping counter: 11/20\n",
      "[Epoch86] train_loss: 0.3638, valid_loss: 2.0580\n",
      "EarlyStopping counter: 12/20\n",
      "[Epoch87] train_loss: 0.3675, valid_loss: 2.0370\n",
      "[Epoch88] train_loss: 0.3591, valid_loss: 2.0454\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch89] train_loss: 0.3668, valid_loss: 2.0524\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch90] train_loss: 0.3660, valid_loss: 2.0590\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch91] train_loss: 0.3577, valid_loss: 2.0527\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch92] train_loss: 0.3546, valid_loss: 2.0472\n",
      "EarlyStopping counter: 5/20\n",
      "[Epoch93] train_loss: 0.3652, valid_loss: 2.0532\n",
      "EarlyStopping counter: 6/20\n",
      "[Epoch94] train_loss: 0.3527, valid_loss: 2.0772\n",
      "EarlyStopping counter: 7/20\n",
      "[Epoch95] train_loss: 0.3575, valid_loss: 2.0487\n",
      "EarlyStopping counter: 8/20\n",
      "[Epoch96] train_loss: 0.3368, valid_loss: 2.0564\n",
      "EarlyStopping counter: 9/20\n",
      "[Epoch97] train_loss: 0.3423, valid_loss: 2.0719\n",
      "EarlyStopping counter: 10/20\n",
      "[Epoch98] train_loss: 0.3366, valid_loss: 2.0748\n",
      "EarlyStopping counter: 11/20\n",
      "[Epoch99] train_loss: 0.3360, valid_loss: 2.0579\n",
      "EarlyStopping counter: 12/20\n",
      "[Epoch100] train_loss: 0.3335, valid_loss: 2.0946\n",
      "EarlyStopping counter: 13/20\n",
      "[Epoch101] train_loss: 0.3336, valid_loss: 2.0517\n",
      "EarlyStopping counter: 14/20\n",
      "[Epoch102] train_loss: 0.3493, valid_loss: 2.0408\n",
      "EarlyStopping counter: 15/20\n",
      "[Epoch103] train_loss: 0.3380, valid_loss: 2.0502\n",
      "EarlyStopping counter: 16/20\n",
      "[Epoch104] train_loss: 0.3407, valid_loss: 2.0400\n",
      "EarlyStopping counter: 17/20\n",
      "[Epoch105] train_loss: 0.3424, valid_loss: 2.0056\n",
      "[Epoch106] train_loss: 0.3268, valid_loss: 2.0280\n",
      "EarlyStopping counter: 1/20\n",
      "[Epoch107] train_loss: 0.3230, valid_loss: 2.0253\n",
      "EarlyStopping counter: 2/20\n",
      "[Epoch108] train_loss: 0.3269, valid_loss: 2.0575\n",
      "EarlyStopping counter: 3/20\n",
      "[Epoch109] train_loss: 0.3407, valid_loss: 2.0350\n",
      "EarlyStopping counter: 4/20\n",
      "[Epoch110] train_loss: 0.3237, valid_loss: 2.0361\n",
      "EarlyStopping counter: 5/20\n",
      "[Epoch111] train_loss: 0.3213, valid_loss: 2.0131\n",
      "EarlyStopping counter: 6/20\n",
      "[Epoch112] train_loss: 0.3131, valid_loss: 2.0442\n",
      "EarlyStopping counter: 7/20\n",
      "[Epoch113] train_loss: 0.3186, valid_loss: 2.0118\n",
      "EarlyStopping counter: 8/20\n",
      "[Epoch114] train_loss: 0.3191, valid_loss: 2.0410\n",
      "EarlyStopping counter: 9/20\n",
      "[Epoch115] train_loss: 0.3095, valid_loss: 2.0221\n",
      "EarlyStopping counter: 10/20\n",
      "[Epoch116] train_loss: 0.3131, valid_loss: 2.0275\n",
      "EarlyStopping counter: 11/20\n",
      "[Epoch117] train_loss: 0.3226, valid_loss: 2.0193\n",
      "EarlyStopping counter: 12/20\n",
      "[Epoch118] train_loss: 0.3167, valid_loss: 2.0242\n",
      "EarlyStopping counter: 13/20\n",
      "[Epoch119] train_loss: 0.3012, valid_loss: 2.0406\n",
      "EarlyStopping counter: 14/20\n",
      "[Epoch120] train_loss: 0.3066, valid_loss: 2.0401\n",
      "EarlyStopping counter: 15/20\n",
      "[Epoch121] train_loss: 0.3171, valid_loss: 2.0454\n",
      "EarlyStopping counter: 16/20\n",
      "[Epoch122] train_loss: 0.3123, valid_loss: 2.0424\n",
      "EarlyStopping counter: 17/20\n",
      "[Epoch123] train_loss: 0.3037, valid_loss: 2.0470\n",
      "EarlyStopping counter: 18/20\n",
      "[Epoch124] train_loss: 0.3024, valid_loss: 2.0436\n",
      "EarlyStopping counter: 19/20\n",
      "[Epoch125] train_loss: 0.3022, valid_loss: 2.0286\n",
      "EarlyStopping counter: 20/20\n",
      "early stopping\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "while True:\n",
    "    epoch+=1\n",
    "    train_loss = train(model,trainloader,args)\n",
    "    valid_loss = eval(model,validloader,args)\n",
    "    print(f'[Epoch{epoch}] train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}')\n",
    "    early_stopper(valid_loss,model)\n",
    "    if early_stopper.early_stop:\n",
    "        print('early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded best model \"ckpts/Solubility_ECFP_MLP_h64b128_lr0.0001.pt\", valid loss: 2.0056\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(early_stopper.path, map_location=args.device))\n",
    "model.eval()\n",
    "print(f'loaded best model \"{early_stopper.path}\", valid loss: {early_stopper.val_loss_min:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solubility_AqSolDB: Final test loss: 1.8527\n"
     ]
    }
   ],
   "source": [
    "test_loss = eval(model,testloader,args)\n",
    "print(f'{dataset}: Final test loss: {test_loss:.4f}')\n",
    "\n",
    "# [A] Solubility_AqSolDB: Final test loss: 1.8527 - MSE\n",
    "# [D] BBB_Martins: Final test loss: 0.3858 - BCE\n",
    "# [M] CYP3A4_Veith: Final test loss: 0.4666 - BCE\n",
    "# [E] Clearance_Hepatocyte_AZ: Final test loss: 3122.5181 - MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MTL",
   "language": "python",
   "name": "mtl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
